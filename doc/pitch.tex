\documentclass[a4paper,11pt]{article}
\usepackage[top=3cm,left=3cm,right=3cm, bottom=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage[spanish]{babel}
\usepackage{amssymb,amsmath}
% \usepackage{eurosym}
\usepackage[utf8,svgnames]{xcolor}
\usepackage{listings}

\parindent 0mm
\parskip 1ex plus 1pt minus 1pt

\title{1st Assignment: Pitch Estimation and Voicing Detection}
\author{Speech Technologies\\\\
José A. R. Fonollosa \& Antonio Bonafonte\\
Universitat Politècnica de Catalunya}
\date{February 27, 2017}


\newcommand{\comment}[1]{
  % \vspace{1mm}
  \begin{center}
    \fboxsep 2mm
    \fcolorbox{orange}{orange!15}{
      \parbox[t]{0.9\textwidth}{
%        {\tiny \bf [REVIEWER \#1]}\\[0ex]
        \small
        \color{DarkBlue}
        #1
        \vspace{0mm}
      }
    }
  \end{center}

  \vspace{3mm}
}


\begin{document}

\maketitle

\comment{The objective of this assignment is the analysis of basic properties of the speech signal: voicing and pitch, and to develop accurate estimation algorithms of these parameters.}


\subsection*{Assignment}

\begin{enumerate}
\item Select at least two algorithms for pitch estimation and voicing detection.
\item Implement the selected methods in any language (C++, python or MATLAB) and compare their performance on the FDA-UE database. You can use the provided \emph{pitch.py} and \emph{test.sh} scripts as starting point or reference. The \emph{pitch.py} script uses a basic algorithm based on the autocorrelation to compute the pitch, while the \emph{test.sh} script shows how to evaluate the performance of a method.
\item Try to improve the results with the use of standard pre- and post-processing methods, new algorithms, a combination of systems, parameter tuning or machine learning algorithms. You can use the PTDB-TUB for tuning and training and keep the FDA-UE database just for the final evaluation.
\item Use the provided C++ 'pitch\_compare' program to report the results as v/uv errors, uv/v errors, gross pitch errors (>20\%) and MSE (Mean Squared Error) of the relative fine pitch errors. (See the \emph{test.sh} script)
\item Report the results of the assignment using a 4-pages paper format. You can use, for instance, the templates in \url{http://www.icassp2016.com/papers/PaperKit.html#Templates}. In the report you have to briefly describe the selected algorithms and initial source code including the corresponding references. Then you have to mention your experiments or original contributions and the obtained results.
\item Upload the complete source code to a git repository (as github) and provide a link to it in the report.
\end{enumerate}

\newpage

\subsection*{Databases}
We have prepared two databases for the development and testing of the pitch estimation and voicing detection algorithms. You can download both of them and the provided initial programs following the links provided on Atenea,

\begin{enumerate}
\item Test database: \textbf{FDA-UE} (sampling rate = 20KHz, frame shift = 15 ms)\\
The Fundamental Frequency Determination Algorithm Evaluation Database (FDA-UE) was prepared by Paul Bagshaw, Centre for Speech Technology Research, University of Edinburgh. The original database includes audio files (20k, 16bit) and a file with the f0 contour obtained from a second file that contains the output of a laryngograph. This apparatus measures impedance between the sensors that are connected to both sides of the larynx, whereby the contour obtained can be used as a reference. We have made a change in format, so that our audio files are in .wav format (instead of raw format), and f0 contours of reference (.f0ref) are interpolated every \textbf{15 ms}.
\item Training database. \textbf{PTDB-TUB} (sampling rate = 48KHz, frame shift = 10 ms)\\
The Pitch Tracking Database from Graz University of Technology (PTDB-TUG) is a speech database for pitch tracking that provides microphone and laryngograph signals of 20 English native speakers as well as the extracted pitch trajectories as a reference. The subjects had to read 2342 phonetically rich sentences from the existing TIMIT corpus. This text material is available spoken by both, female and male speakers. In total, this database consists of 4720 recorded sentences. All recordings were carried out on-site at the recording studio of the Institute of Broadband Communications at Graz University of Technology. In the version of this database provided for this work, we keep the audio files in the original .wav format with a sampling rate of 48KHz, but we have reformatted the f0 contours of reference (.f0ref) as in the previous database. However, in this database the f0 of reference are computed every \textbf{10 ms} with a window of 32ms.
\end{enumerate}


\subsection*{Pitch estimation and voicing detection program}

For each .wav file, your program should output a text file with extension .f0 and a line every 15 milliseconds (FDA-UE) or 10 milliseconds (PTDB-TUG), indicating the fundamental frequency in Hz. If the segment is unvoiced, you must write a line with a ’0’.\\
You can use the provided \emph{pitch.py} script as a starting point or reference. The program \emph{pitch.py} need an argument: FILELIST (a file with the list of files to process without the .wav extension) and it has three options:
\begin{lstlisting}
Usage: pitch.py [OPTION]... FILELIST
Options:
  -h, --help            show this help message and exit
  -w WINDOWLENGTH, --windowlength=WINDOWLENGTH
                        windows length (ms)
  -f FRAMELENGTH, --framelength=FRAMELENGTH
                        frame shift (ms)
  -d DATADIR, --datadir=DATADIR
                        root data folder
\end{lstlisting}


\subsection*{Evaluation}
Once you have all the files with the detected pitch, (extension .f0), which must be in the same directory as the reference files (extension .f0ref), you can execute the pitch\_compare program to evaluate your method.\\

After compiling the program:
\begin{lstlisting}
$ g++ pitch_compare.cpp -o pitch\_compare
\end{lstlisting}
you can call it with the same FILELIST as argument
\begin{lstlisting}
$ ./pitch_compare FILELIST
\end{lstlisting}
This program calculates, for each file:
\begin{itemize}
\item Voiced frames -> unvoiced (1 - recall voiced)\\
  Number of unvoiced frames that have been erroneously classified as voiced.
\item Unvoiced frames -> voiced: (1 - recall unvoiced)\\
  Number of voiced frames that have been erroneously classified as unvoiced.
\item Gross voiced errors:\\
  In voiced frames, detected as voiced,\\
  Pitch errors greater than 20\%
\item MSE of fine errors:\\
  In voiced frames, detected as voiced with an error less than 20\%,\\
  the average of that error. (Mean Squared Error)
\end{itemize}
It also provides a summary with the average over all files.

\subsection*{License}
\begin{enumerate}
\item More details about the FDA-UE database can be found in \url{http://www.cstr.ed.ac.uk/research/projects/fda/}
\item More details about the PTDB-TUB database can be found in G. Pirker, M. Wohlmayr, S. Petrik, and F. Pernkopf. \href{https://www.spsc.tugraz.at/system/files/InterSpeech2011Master_0.pdf}{"A Pitch Tracking Corpus with Evaluation on Multipitch Tracking Scenario"}, Interspeech, pp. 1509-1512, 2011.\\
This PTDB-TUG Database is made available under the Open Database License: \url{http://opendatacommons.org/licenses/odbl/1.0/} Any rights in individual contents of the database are licensed under the Database Contents License: \url{http://opendatacommons.org/licenses/dbcl/1.0/} Please cite the above given reference when using the database. 
\end{enumerate}

\end{document}
